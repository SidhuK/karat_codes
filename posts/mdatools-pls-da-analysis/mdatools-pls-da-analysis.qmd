---
title: "MDATools - PLS-DA Analysis"
description: |
  A short description of the post.
author:
  - name: Karat Sidhu
    url: {}
date: 2022-05-26
categories:
  - PLS-DA
  - Machine Learning
  - Discriminant Analysis
  - Dimension Reduction
  - Algorithm
toc: true
toc-title: Table of contents
toc-location: left
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


https://mdatools.com/docs/plsda.html

https://towardsdatascience.com/partial-least-squares-f4e6714452a





```{r}



library(mdatools)

data(iris)

cal.ind = c(1:25, 51:75, 101:125)
val.ind = c(26:50, 76:100, 126:150)

Xc = iris[cal.ind, 1:4]
Xv = iris[val.ind, 1:4]

cc.all = iris[cal.ind, 5]
cv.all = iris[val.ind, 5]


show(cc.all)


cc.vir = cc.all == "virginica"
cv.vir = cv.all == "virginica"
show(cc.vir)

```

```{r}

# Now we can calibrate the models:  
  
m.all = plsda(Xc, cc.all, 3, cv = 1)
m.vir = plsda(Xc, cc.vir, 3, cv = 1, classname = "virginica")

summary(m.all)


summary(m.all, nc = 3)


summary(m.all$calres, nc = 3)


summary(m.vir)



getConfusionMatrix(m.all$calres)


getConfusionMatrix(m.vir$calres)


```



```{r}

par(mfrow = c(1, 2))
plotPredictions(m.all)
plotPredictions(m.vir)


par(mfrow = c(1, 2))
plotPredictions(m.all, nc = 1)
plotPredictions(m.all, nc = 3)


par(mfrow = c(3, 2))
plotMisclassified(m.all, nc = 2)
plotMisclassified(m.vir)
plotSensitivity(m.all, nc = 2)
plotSensitivity(m.vir)
plotSpecificity(m.all, nc = 2)
plotSpecificity(m.vir)



par(mfrow = c(1, 2))
plotRegcoeffs(m.all, ncomp = 3, ny = 3)
plotRegcoeffs(m.vir, ncomp = 1, show.ci = TRUE)


res = predict(m.all, Xv, cv.all)
summary(res)


par(mfrow = c(1, 1))
plotPredictions(res)


res21 = predict(m.vir, Xv, cv.all)
summary(res21)


res22 = predict(m.vir, Xv, cv.vir)
summary(res22)


par(mfrow = c(2, 1))
plotPredictions(res21)
plotPredictions(res22)


par(mfrow = c(1, 2))
plotXResiduals(res21)
plotYVariance(res22)


```


